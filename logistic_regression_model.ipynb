{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from assignment1_Kaustav import *\n",
    "#from assignment1_Finn import *\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, theta):\n",
    "    m = len(y)\n",
    "    h = sigmoid(X @ theta)\n",
    "    epsilon = 1e-5\n",
    "    cost = (1/m)*(((-y).T @ np.log(h + epsilon))-((1-y).T @ np.log(1-h + epsilon)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, params, learning_rate, iterations):\n",
    "    m = len(y)\n",
    "    cost_history = np.zeros((iterations,1))\n",
    "\n",
    "    for i in range(iterations):\n",
    "        params = params - (learning_rate/m) * (X.T @ (sigmoid(X @ params) - y)) \n",
    "        cost_history[i] = compute_cost(X, y, params)\n",
    "\n",
    "    return (cost_history, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, params):\n",
    "    return np.round(sigmoid(X @ params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# features = df.drop(['salary'] , axis=1)\n",
    "# X = features.values\n",
    "# output = df['salary']\n",
    "# y = output.values\n",
    "\n",
    "features = DataFrame.drop(['mpg'] , axis=1)\n",
    "X = features.values\n",
    "output = DataFrame['mpg']\n",
    "y = output.values\n",
    "\n",
    "y = y[:,np.newaxis]\n",
    "sns.set_style('white')\n",
    "sns.scatterplot(X[:,0],X[:,1],hue=y.reshape(-1));\n",
    "\n",
    "m = len(y)\n",
    "\n",
    "X = np.hstack((np.ones((m,1)),X))\n",
    "n = np.size(X,1)\n",
    "params = np.zeros((n,1))\n",
    "\n",
    "iterations = 4000\n",
    "learning_rate = 0.03\n",
    "\n",
    "initial_cost = compute_cost(X, y, params)\n",
    "\n",
    "print(\"Initial Cost is: {} \\n\".format(initial_cost))\n",
    "\n",
    "(cost_history, params_optimal) = gradient_descent(X, y, params, learning_rate, iterations)\n",
    "\n",
    "print(\"Optimal Parameters are: \\n\", params_optimal, \"\\n\")\n",
    "\n",
    "plt.figure()\n",
    "sns.set_style('white')\n",
    "plt.plot(range(len(cost_history)), cost_history, 'r')\n",
    "plt.title(\"Convergence Graph of Cost Function\")\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred = predict(X, params_optimal)\n",
    "score = float(sum(y_pred == y))/ float(len(y))\n",
    "\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
