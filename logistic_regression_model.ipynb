{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.style as style\n",
    "\n",
    "%run Preprocessing_BCW_Data.ipynb\n",
    "%run Preprocessing_Adult_Data.ipynb\n",
    "%run Preprocessing_Ionosphere_Data.ipynb\n",
    "%run preprocessing_mpg_dataset.ipynb\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kFoldCrossVal(k, X, y, rate, iter):\n",
    "    accuracy = 0\n",
    "    model = LogisticRegression()\n",
    "    \n",
    "    size = (int)(len(y)/k)\n",
    "    for i in range(k):\n",
    "        train_x = X[np.r_[0:size*i, size*(i+1):]]\n",
    "        train_y = y[np.r_[0:size*i, size*(i+1):]]\n",
    "        test_x = X[(i*size):size*(i+1)]\n",
    "        test_y = y[(i*size):size*(i+1)]\n",
    "        \n",
    "        (cost_history, params_optimal) = lr.fit(train_x, train_y, params, rate, iter)\n",
    "        y_pred = lr.predict(test_x, params_optimal)\n",
    "        run_accuracy = lr.evaluate_acc(test_y, y_pred)\n",
    "        accuracy = accuracy + run_accuracy\n",
    "    \n",
    "    return accuracy/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def compute_cost(self, X, y, theta):\n",
    "        m = len(y)\n",
    "        h = self.sigmoid(X @ theta)\n",
    "        epsilon = 1e-5\n",
    "        cost = (1/m)*(((-y).T @ np.log(h + epsilon))-((1-y).T @ np.log(1-h + epsilon)))\n",
    "        return cost\n",
    "\n",
    "    def fit(self, X, y, params, learning_rate, iterations):\n",
    "        m = len(y)\n",
    "        cost_history = np.zeros((iterations,1))\n",
    "\n",
    "        for i in range(iterations):\n",
    "            params = params - (learning_rate/m) * (X.T @ (self.sigmoid(X @ params) - y)) \n",
    "            cost_history[i] = self.compute_cost(X, y, params)\n",
    "\n",
    "        return (cost_history, params)\n",
    "\n",
    "    \n",
    "    def predict(self, X, params):\n",
    "        return np.round(self.sigmoid(X @ params))\n",
    "\n",
    "    def evaluate_acc(self, test_y, predicted_y):\n",
    "        return (np.sum(predicted_y == test_y) / len(test_y))\n",
    "\n",
    "iterations= []\n",
    "for i in range(10,20):\n",
    "    iterations.append(100*i)\n",
    "    \n",
    "# for i in range(1,11):\n",
    "#     iterations.append(10*i)\n",
    "    \n",
    "learning_rate= [0.0001,0.0002,0.0003,0.0004,0.0005,0.0006,0.0007,0.0008,0.0009,\n",
    "               0.001,0.002,0.003,0.004,0.005,0.006,0.007,0.008,0.009,\n",
    "               0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,\n",
    "               0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "\n",
    "# learning_rate= [0.0001, 0.001, 0.01, 0.1]\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# features = df.drop(['salary'] , axis=1)\n",
    "# X = features.values\n",
    "# output = df['salary']\n",
    "# y = output.values\n",
    "\n",
    "# features = df_ion.drop(['classification'] , axis=1)\n",
    "# X = features.values\n",
    "# output = df_ion['classification']\n",
    "# y = output.values\n",
    "\n",
    "# features = DataFrame.drop(['mpg'] , axis=1)\n",
    "# X = features.values\n",
    "# output = DataFrame['mpg']\n",
    "# y = output.values\n",
    "\n",
    "# features = df_bcw.drop(['Class'] , axis=1)\n",
    "# X = features.values\n",
    "# output = df_bcw['Class']\n",
    "# y = output.values\n",
    "\n",
    "y = y[:,np.newaxis]\n",
    "sns.set_style('white')\n",
    "fig = sns.scatterplot(X[:,0],X[:,1],hue=y.reshape(-1));\n",
    "m = len(y)\n",
    "X = np.hstack((np.ones((m,1)),X))\n",
    "n = np.size(X,1)\n",
    "params = np.zeros((n,1))\n",
    "initial_cost = lr.compute_cost(X, y, params)\n",
    "\n",
    "optimal_score = 0\n",
    "optimal_rate = 0\n",
    "optimal_iter = 0\n",
    "\n",
    "for rate in learning_rate:\n",
    "    for iter in iterations:\n",
    "        score = kFoldCrossVal(5, X, y, rate, iter)\n",
    "#         (cost_history, params_optimal) = lr.fit(X, y, params, rate, iter)\n",
    "#         y_pred = lr.predict(X, params_optimal)\n",
    "#         score = float(sum(y_pred == y))/ float(len(y))\n",
    "        \n",
    "        if score > optimal_score:\n",
    "            optimal_score = score\n",
    "            optimal_rate = rate\n",
    "            optimal_iter = iter\n",
    "\n",
    "print(\"Optimal score is {}, with rate: {} and {} iterations\".format(optimal_score, optimal_rate, optimal_iter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
